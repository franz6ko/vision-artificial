{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de8074d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "%matplotlib\n",
    "\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccfcf795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos los clasificadores pre-entrenados\n",
    "face_cascade = cv.CascadeClassifier('/home/fran6ko/anaconda3/envs/datos/share/opencv4/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv.CascadeClassifier('/home/fran6ko/anaconda3/envs/datos/share/opencv4/haarcascades/haarcascade_eye.xml')\n",
    "smile_cascade = cv.CascadeClassifier('/home/fran6ko/anaconda3/envs/datos/share/opencv4/haarcascades/haarcascade_smile.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548bd52e",
   "metadata": {},
   "source": [
    "## Static Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fcf05ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv.VideoCapture(0)\n",
    "\n",
    "ret,frame = camera.read()\n",
    "cv.imshow('Foto',frame)\n",
    "\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8515131",
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_eye_smile_detection(img):\n",
    "\n",
    "    # Cargamos la imagen a analizar\n",
    "    originalImage = img.copy()\n",
    "\n",
    "    # Pasamos la imagen a escala de grises\n",
    "    grayImage = cv.cvtColor(originalImage, cv.COLOR_BGR2GRAY)\n",
    "    grayImage = cv.equalizeHist(grayImage)\n",
    "\n",
    "    # Llamamos al clasificador de Haar (AdaBoost)\n",
    "    faces = face_cascade.detectMultiScale(grayImage, 1.1, 5, minSize=(200, 200))\n",
    "\n",
    "    # Extra data\n",
    "    eyes_res = None\n",
    "    \n",
    "    # Recorro las caras encontradas\n",
    "    for (x,y,w,h) in faces:\n",
    "        # Le dibujamos un rectángulo amarillo\n",
    "        cv.rectangle(originalImage,(x,y),(x+w,y+h),(255,255,0),4)\n",
    "        # Definimos las ROIs en la imagen gris y color\n",
    "        roi_gray = grayImage[y:y+h, x:x+w] \n",
    "        roi_color = originalImage[y:y+h, x:x+w]\n",
    "        # Para cada rostro hallado le buscamos los ojos\n",
    "        e = int(w/5)\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray, 1.1, 7, minSize=(e,e))\n",
    "        # En los ojos hallados les dibujamos rectángulos\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "        # Para cada rostro hallado le buscamos las sonrisas\n",
    "        s = int(w/6)\n",
    "        smiles = smile_cascade.detectMultiScale(roi_gray, 1.3, 17, minSize=(2*s,s))\n",
    "        # En las sonrisas halladas les dibujamos rectángulos\n",
    "        for (ex,ey,ew,eh) in smiles:\n",
    "            #cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,0,255),2)\n",
    "            triangle = np.array([[[ex, ey], [ex+ew, ey], [ex+int(ew/2), ey+eh]]], np.int32)\n",
    "            cv.polylines(roi_color, [triangle], True, (0,0,255), thickness=3)\n",
    "        # Devolver ojos si se encontraron exactamente 2\n",
    "        if len(eyes) == 2:\n",
    "            eyes_res = eyes + [x, y, 0, 0]\n",
    "    \n",
    "    return originalImage, eyes_res\n",
    "            \n",
    "res,_ = face_eye_smile_detection(frame)\n",
    "    \n",
    "cv.imshow('Deteccion de caras con filtros de Haar en cascada',res) \n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0dc408b",
   "metadata": {},
   "source": [
    "## Dynamic Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee85e9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "term_crit = ( cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 1, 10 )\n",
    "\n",
    "camera = cv.VideoCapture(0)\n",
    "\n",
    "while(1):\n",
    "    ret, frame = camera.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        res,_ = face_eye_smile_detection(frame)\n",
    "        cv.imshow('Live Detection', res) \n",
    "        \n",
    "        # If the ESC kay is pressed, stop the execution\n",
    "        k = cv.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cv.destroyAllWindows()\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57c2628",
   "metadata": {},
   "source": [
    "## Glasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cabddd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "qty = 3\n",
    "lentes = [cv.imread(\"lentes\" + str(i) + \".png\", cv.IMREAD_UNCHANGED) for i in range(qty)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0906406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion para mezclar 2 imagenes (https://www.programcreek.com/python/example/89436/cv2.addWeighted - Examlple 4)\n",
    "\n",
    "def blend_transparent(face_img, overlay_t_img):\n",
    "    # Split out the transparency mask from the colour info\n",
    "    overlay_img = overlay_t_img[:, :, :3]  # Grab the BRG planes\n",
    "    overlay_mask = overlay_t_img[:, :, 3:]  # And the alpha plane\n",
    "\n",
    "    # Again calculate the inverse mask\n",
    "    background_mask = 255 - overlay_mask\n",
    "\n",
    "    # Turn the masks into three channel, so we can use them as weights\n",
    "    overlay_mask = cv.cvtColor(overlay_mask, cv.COLOR_GRAY2BGR)\n",
    "    background_mask = cv.cvtColor(background_mask, cv.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Create a masked out face image, and masked out overlay\n",
    "    # We convert the images to floating point in range 0.0 - 1.0\n",
    "    face_part = (face_img * (1 / 255.0)) * (background_mask * (1 / 255.0))\n",
    "    overlay_part = (overlay_img * (1 / 255.0)) * (overlay_mask * (1 / 255.0))\n",
    "\n",
    "    # And finally just add them together, and rescale it back to an 8bit integer image\n",
    "    return np.uint8(cv.addWeighted(face_part, 255.0, overlay_part, 255.0, 0.0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57e700b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "previous_eyes = None\n",
    "\n",
    "def put_glasses(img, glasses):\n",
    "    \n",
    "    global previous_eyes, counter\n",
    "\n",
    "    res,eyes = face_eye_smile_detection(img)\n",
    "    \n",
    "    if eyes is None:\n",
    "        if previous_eyes is None:\n",
    "            return img\n",
    "        else:\n",
    "            if counter > 5:\n",
    "                return img\n",
    "            else:\n",
    "                counter = counter + 1\n",
    "                eyes = previous_eyes\n",
    "    else:\n",
    "        counter = 0\n",
    "        previous_eyes = eyes\n",
    "    \n",
    "    dist_res = np.linalg.norm(eyes[0,:2] - eyes[1,:2])\n",
    "\n",
    "    lentes = glasses.copy()\n",
    "    face = img.copy()\n",
    "\n",
    "    dist = lentes.shape[1]/2\n",
    "    scale_factor = dist_res/dist * 1.3\n",
    "    new_size = (int(lentes.shape[1]*scale_factor), int(lentes.shape[0]*scale_factor))\n",
    "    lentes = cv.resize(lentes, new_size)\n",
    "\n",
    "    left_eye = eyes[0] if eyes[0,0] < eyes[1,0] else eyes[1]\n",
    "\n",
    "    x_offset = left_eye[0] + int(left_eye[2]/2) - int(new_size[0]/3.2)\n",
    "    y_offset = int((eyes[0,1] +  eyes[1,1])/2) + int(left_eye[3]/2) - int(new_size[1]/2)\n",
    "\n",
    "    roi = face[y_offset:y_offset+new_size[1], x_offset:x_offset+new_size[0]]\n",
    "    face[y_offset:y_offset+new_size[1], x_offset:x_offset+new_size[0]] = blend_transparent(roi, lentes)\n",
    "\n",
    "    return face\n",
    "    \n",
    "res = put_glasses(frame, lentes[0])\n",
    "cv.imshow('Static Glasses',res) \n",
    "    \n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5cf793",
   "metadata": {},
   "source": [
    "## Dynamic Glasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "803f301e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "term_crit = ( cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 1, 10 )\n",
    "\n",
    "camera = cv.VideoCapture(0)\n",
    "\n",
    "idx = 0\n",
    "\n",
    "while(1):\n",
    "    ret, frame = camera.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        res = put_glasses(frame, lentes[idx])\n",
    "        cv.imshow('Live Glasses', res) \n",
    "        \n",
    "        # If the ESC kay is pressed, stop the execution\n",
    "        k = cv.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            break\n",
    "        \n",
    "        # Switch glasses with A/D arrows\n",
    "        if k == 100:\n",
    "            idx = idx + 1\n",
    "            if idx == len(lentes):\n",
    "                idx = 0\n",
    "        if k == 97:\n",
    "            idx = idx - 1\n",
    "            if idx == -1:\n",
    "                idx = len(lentes) - 1\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cv.destroyAllWindows()\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898c8223",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
